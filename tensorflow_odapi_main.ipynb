{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow_odapi_main.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Masum06/nudefilterdata/blob/master/tensorflow_odapi_main.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Yhi7NcNiPhos",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "980ce322-1451-44c3-f027-0a285af1fa5f"
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b5q0DlyyMK9s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "3e779a03-9ac0-4168-d2bc-8f4dfc1be98a"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Counting objects: 21560, done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 21560 (delta 0), reused 0 (delta 0), pack-reused 21553\u001b[K\n",
            "Receiving objects: 100% (21560/21560), 558.40 MiB | 29.88 MiB/s, done.\n",
            "Resolving deltas: 100% (12728/12728), done.\n",
            "Checking out files: 100% (2670/2670), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tWd1YOL2gUrK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3183
        },
        "outputId": "723d5d0a-ba83-4bfd-db1d-cb4d14f5dfca"
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "pip install Cython\n",
        "pip install contextlib2\n",
        "pip install jupyter\n",
        "pip install matplotlib"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "python-tk is already the newest version (2.7.14-1).\n",
            "The following additional packages will be installed:\n",
            "  libjbig0 liblcms2-2 libprotobuf10 libprotoc10 libtiff5 libwebp6 libwebpmux3\n",
            "  libxslt1.1 python-bs4 python-chardet python-html5lib python-olefile\n",
            "  python-pkg-resources python-six python-webencodings\n",
            "Suggested packages:\n",
            "  liblcms2-utils python-genshi python-lxml-dbg python-lxml-doc python-pil-doc\n",
            "  python-pil-dbg python-setuptools\n",
            "The following NEW packages will be installed:\n",
            "  libjbig0 liblcms2-2 libprotobuf10 libprotoc10 libtiff5 libwebp6 libwebpmux3\n",
            "  libxslt1.1 protobuf-compiler python-bs4 python-chardet python-html5lib\n",
            "  python-lxml python-olefile python-pil python-pkg-resources python-six\n",
            "  python-webencodings\n",
            "0 upgraded, 18 newly installed, 0 to remove and 0 not upgraded.\n",
            "Need to get 3,751 kB of archives.\n",
            "After this operation, 14.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu artful/main amd64 libjbig0 amd64 2.1-3.1 [26.6 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu artful/main amd64 liblcms2-2 amd64 2.7-1ubuntu1 [137 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu artful/main amd64 libprotobuf10 amd64 3.0.0-9ubuntu5 [650 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu artful/main amd64 libprotoc10 amd64 3.0.0-9ubuntu5 [565 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu artful-updates/main amd64 libtiff5 amd64 4.0.8-5ubuntu0.1 [150 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu artful/main amd64 libwebp6 amd64 0.6.0-3 [181 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu artful/main amd64 libwebpmux3 amd64 0.6.0-3 [20.0 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu artful/main amd64 libxslt1.1 amd64 1.1.29-2.1ubuntu1 [149 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu artful/main amd64 python-bs4 all 4.6.0-1 [67.9 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu artful/main amd64 python-pkg-resources all 36.2.7-2 [128 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu artful/main amd64 python-chardet all 3.0.4-1 [80.3 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu artful/main amd64 python-six all 1.10.0-4 [10.8 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu artful/main amd64 python-webencodings all 0.5-2 [10.3 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu artful/main amd64 python-html5lib all 0.999999999-1 [83.6 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu artful/main amd64 python-lxml amd64 4.0.0-1 [1,120 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu artful/main amd64 python-olefile all 0.44-1 [36.2 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu artful/main amd64 python-pil amd64 4.1.1-3build2 [311 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu artful/main amd64 protobuf-compiler amd64 3.0.0-9ubuntu5 [24.5 kB]\n",
            "Fetched 3,751 kB in 0s (24.3 MB/s)\n",
            "Selecting previously unselected package libjbig0:amd64.\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 18408 files and directories currently installed.)\r\n",
            "Preparing to unpack .../00-libjbig0_2.1-3.1_amd64.deb ...\r\n",
            "Unpacking libjbig0:amd64 (2.1-3.1) ...\r\n",
            "Selecting previously unselected package liblcms2-2:amd64.\r\n",
            "Preparing to unpack .../01-liblcms2-2_2.7-1ubuntu1_amd64.deb ...\r\n",
            "Unpacking liblcms2-2:amd64 (2.7-1ubuntu1) ...\r\n",
            "Selecting previously unselected package libprotobuf10:amd64.\r\n",
            "Preparing to unpack .../02-libprotobuf10_3.0.0-9ubuntu5_amd64.deb ...\r\n",
            "Unpacking libprotobuf10:amd64 (3.0.0-9ubuntu5) ...\r\n",
            "Selecting previously unselected package libprotoc10:amd64.\r\n",
            "Preparing to unpack .../03-libprotoc10_3.0.0-9ubuntu5_amd64.deb ...\r\n",
            "Unpacking libprotoc10:amd64 (3.0.0-9ubuntu5) ...\r\n",
            "Selecting previously unselected package libtiff5:amd64.\r\n",
            "Preparing to unpack .../04-libtiff5_4.0.8-5ubuntu0.1_amd64.deb ...\r\n",
            "Unpacking libtiff5:amd64 (4.0.8-5ubuntu0.1) ...\r\n",
            "Selecting previously unselected package libwebp6:amd64.\r\n",
            "Preparing to unpack .../05-libwebp6_0.6.0-3_amd64.deb ...\r\n",
            "Unpacking libwebp6:amd64 (0.6.0-3) ...\r\n",
            "Selecting previously unselected package libwebpmux3:amd64.\r\n",
            "Preparing to unpack .../06-libwebpmux3_0.6.0-3_amd64.deb ...\r\n",
            "Unpacking libwebpmux3:amd64 (0.6.0-3) ...\r\n",
            "Selecting previously unselected package libxslt1.1:amd64.\r\n",
            "Preparing to unpack .../07-libxslt1.1_1.1.29-2.1ubuntu1_amd64.deb ...\r\n",
            "Unpacking libxslt1.1:amd64 (1.1.29-2.1ubuntu1) ...\r\n",
            "Selecting previously unselected package python-bs4.\r\n",
            "Preparing to unpack .../08-python-bs4_4.6.0-1_all.deb ...\r\n",
            "Unpacking python-bs4 (4.6.0-1) ...\r\n",
            "Selecting previously unselected package python-pkg-resources.\r\n",
            "Preparing to unpack .../09-python-pkg-resources_36.2.7-2_all.deb ...\r\n",
            "Unpacking python-pkg-resources (36.2.7-2) ...\r\n",
            "Selecting previously unselected package python-chardet.\r\n",
            "Preparing to unpack .../10-python-chardet_3.0.4-1_all.deb ...\r\n",
            "Unpacking python-chardet (3.0.4-1) ...\r\n",
            "Selecting previously unselected package python-six.\r\n",
            "Preparing to unpack .../11-python-six_1.10.0-4_all.deb ...\r\n",
            "Unpacking python-six (1.10.0-4) ...\r\n",
            "Selecting previously unselected package python-webencodings.\r\n",
            "Preparing to unpack .../12-python-webencodings_0.5-2_all.deb ...\r\n",
            "Unpacking python-webencodings (0.5-2) ...\r\n",
            "Selecting previously unselected package python-html5lib.\r\n",
            "Preparing to unpack .../13-python-html5lib_0.999999999-1_all.deb ...\r\n",
            "Unpacking python-html5lib (0.999999999-1) ...\r\n",
            "Selecting previously unselected package python-lxml.\r\n",
            "Preparing to unpack .../14-python-lxml_4.0.0-1_amd64.deb ...\r\n",
            "Unpacking python-lxml (4.0.0-1) ...\r\n",
            "Selecting previously unselected package python-olefile.\r\n",
            "Preparing to unpack .../15-python-olefile_0.44-1_all.deb ...\r\n",
            "Unpacking python-olefile (0.44-1) ...\r\n",
            "Selecting previously unselected package python-pil:amd64.\r\n",
            "Preparing to unpack .../16-python-pil_4.1.1-3build2_amd64.deb ...\r\n",
            "Unpacking python-pil:amd64 (4.1.1-3build2) ...\r\n",
            "Selecting previously unselected package protobuf-compiler.\r\n",
            "Preparing to unpack .../17-protobuf-compiler_3.0.0-9ubuntu5_amd64.deb ...\r\n",
            "Unpacking protobuf-compiler (3.0.0-9ubuntu5) ...\r\n",
            "Setting up liblcms2-2:amd64 (2.7-1ubuntu1) ...\r\n",
            "Setting up libjbig0:amd64 (2.1-3.1) ...\r\n",
            "Setting up libtiff5:amd64 (4.0.8-5ubuntu0.1) ...\r\n",
            "Setting up python-pkg-resources (36.2.7-2) ...\r\n",
            "Setting up libxslt1.1:amd64 (1.1.29-2.1ubuntu1) ...\r\n",
            "Setting up libprotobuf10:amd64 (3.0.0-9ubuntu5) ...\r\n",
            "Setting up python-six (1.10.0-4) ...\r\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\r\n",
            "Setting up python-bs4 (4.6.0-1) ...\r\n",
            "Setting up python-lxml (4.0.0-1) ...\r\n",
            "Setting up python-olefile (0.44-1) ...\r\n",
            "Setting up libprotoc10:amd64 (3.0.0-9ubuntu5) ...\r\n",
            "Setting up python-webencodings (0.5-2) ...\r\n",
            "Setting up libwebp6:amd64 (0.6.0-3) ...\r\n",
            "Setting up python-chardet (3.0.4-1) ...\r\n",
            "Setting up protobuf-compiler (3.0.0-9ubuntu5) ...\r\n",
            "Setting up libwebpmux3:amd64 (0.6.0-3) ...\r\n",
            "Setting up python-html5lib (0.999999999-1) ...\r\n",
            "Setting up python-pil:amd64 (4.1.1-3build2) ...\r\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\r\n",
            "Collecting Cython\n",
            "  Downloading https://files.pythonhosted.org/packages/19/8e/32b280abb0947a96cdbb8329fb2014851a21fc1d099009f946ea8a8202c3/Cython-0.28.5-cp36-cp36m-manylinux1_x86_64.whl (3.4MB)\n",
            "Installing collected packages: Cython\n",
            "Successfully installed Cython-0.28.5\n",
            "Collecting contextlib2\n",
            "  Downloading https://files.pythonhosted.org/packages/a2/71/8273a7eeed0aff6a854237ab5453bc9aa67deb49df4832801c21f0ff3782/contextlib2-0.5.5-py2.py3-none-any.whl\n",
            "Installing collected packages: contextlib2\n",
            "Successfully installed contextlib2-0.5.5\n",
            "Collecting jupyter\n",
            "  Downloading https://files.pythonhosted.org/packages/83/df/0f5dd132200728a86190397e1ea87cd76244e42d39ec5e88efd25b2abd7e/jupyter-1.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter) (4.6.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter) (5.2.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter) (5.3.1)\n",
            "Collecting jupyter-console (from jupyter)\n",
            "  Downloading https://files.pythonhosted.org/packages/77/82/6469cd7fccf7958cbe5dce2e623f1e3c5e27f1bb1ad36d90519bc2d5d370/jupyter_console-5.2.0-py2.py3-none-any.whl\n",
            "Collecting qtconsole (from jupyter)\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/1f/b340d52dee46fbbe8a097dce76d1197258bb599692159d94c80921fef9eb/qtconsole-4.4.1-py2.py3-none-any.whl (112kB)\n",
            "Collecting ipywidgets (from jupyter)\n",
            "  Downloading https://files.pythonhosted.org/packages/34/3a/5b258ea6d584f5a8527c2295d0ebf7ffb1654e3de38d37697f88bbef6621/ipywidgets-7.4.0-py2.py3-none-any.whl (109kB)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter) (5.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter) (5.2.3)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter) (4.5.3)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter) (4.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter) (2.10)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter) (4.4.0)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter) (0.8.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter) (0.2.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter) (4.4.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (1.4.2)\n",
            "Requirement already satisfied: mistune>=0.7.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.8.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (2.1.3)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (2.1.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.3.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter) (1.0.15)\n",
            "Collecting widgetsnbextension~=3.4.0 (from ipywidgets->jupyter)\n",
            "  Downloading https://files.pythonhosted.org/packages/83/03/ed063ec3ecf499d5491734822d8cadfc80f531a41ae1604277b25fbed795/widgetsnbextension-3.4.0-py2.py3-none-any.whl (2.2MB)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter) (39.1.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter) (0.7.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter) (4.3.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter) (4.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->jupyter) (2.5.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->jupyter) (16.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel->jupyter) (1.11.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->jupyter) (1.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->jupyter) (0.6.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->notebook->jupyter) (2.6.0)\n",
            "Requirement already satisfied: html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter) (1.0.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter) (0.1.7)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre->bleach->nbconvert->jupyter) (0.5.1)\n",
            "Installing collected packages: jupyter-console, qtconsole, widgetsnbextension, ipywidgets, jupyter\n",
            "Successfully installed ipywidgets-7.4.0 jupyter-1.0.0 jupyter-console-5.2.0 qtconsole-4.4.1 widgetsnbextension-3.4.0\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (2.1.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2018.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.14.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UK44VGuIg-Nj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bb2b9cc8-0285-475b-e8bb-9fa95d50ea35"
      },
      "cell_type": "code",
      "source": [
        "cd models/research/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "avhpalMwhZGh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7b355c18-6ad0-4808-b3c5-3cad497f941a"
      },
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CRbAIbtPmRdZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# From tensorflow/models/research/\n",
        "%%bash\n",
        "protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YIaHfDlJhdDK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1219
        },
        "outputId": "ba74719c-e54e-4601-bd46-3ae4178a1583"
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "wget -O protobuf.zip https://github.com/google/protobuf/releases/download/v3.0.0/protoc-3.0.0-linux-x86_64.zip\n",
        "unzip protobuf.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  protobuf.zip\n",
            "   creating: include/\n",
            "   creating: include/google/\n",
            "   creating: include/google/protobuf/\n",
            "  inflating: include/google/protobuf/struct.proto  \n",
            "  inflating: include/google/protobuf/type.proto  \n",
            "  inflating: include/google/protobuf/descriptor.proto  \n",
            "  inflating: include/google/protobuf/api.proto  \n",
            "  inflating: include/google/protobuf/empty.proto  \n",
            "   creating: include/google/protobuf/compiler/\n",
            "  inflating: include/google/protobuf/compiler/plugin.proto  \n",
            "  inflating: include/google/protobuf/any.proto  \n",
            "  inflating: include/google/protobuf/field_mask.proto  \n",
            "  inflating: include/google/protobuf/wrappers.proto  \n",
            "  inflating: include/google/protobuf/timestamp.proto  \n",
            "  inflating: include/google/protobuf/duration.proto  \n",
            "  inflating: include/google/protobuf/source_context.proto  \n",
            "   creating: bin/\n",
            "  inflating: bin/protoc              \n",
            "  inflating: readme.txt              \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--2018-08-29 08:48:44--  https://github.com/google/protobuf/releases/download/v3.0.0/protoc-3.0.0-linux-x86_64.zip\n",
            "Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/protocolbuffers/protobuf/releases/download/v3.0.0/protoc-3.0.0-linux-x86_64.zip [following]\n",
            "--2018-08-29 08:48:44--  https://github.com/protocolbuffers/protobuf/releases/download/v3.0.0/protoc-3.0.0-linux-x86_64.zip\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/23357588/c692d808-54ca-11e6-90f6-ef943b0908bf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20180829%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20180829T084844Z&X-Amz-Expires=300&X-Amz-Signature=bc07a938a37ffb6244a9a41ef659b8a2b8a6264109a1d4b246ed78e768d8389f&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dprotoc-3.0.0-linux-x86_64.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2018-08-29 08:48:44--  https://github-production-release-asset-2e65be.s3.amazonaws.com/23357588/c692d808-54ca-11e6-90f6-ef943b0908bf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20180829%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20180829T084844Z&X-Amz-Expires=300&X-Amz-Signature=bc07a938a37ffb6244a9a41ef659b8a2b8a6264109a1d4b246ed78e768d8389f&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dprotoc-3.0.0-linux-x86_64.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.64.88\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.64.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1296281 (1.2M) [application/octet-stream]\n",
            "Saving to: ‘protobuf.zip’\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  3%  204K 6s\n",
            "    50K .......... .......... .......... .......... ..........  7%  305K 5s\n",
            "   100K .......... .......... .......... .......... .......... 11%  611K 4s\n",
            "   150K .......... .......... .......... .......... .......... 15%  600K 3s\n",
            "   200K .......... .......... .......... .......... .......... 19%  611K 3s\n",
            "   250K .......... .......... .......... .......... .......... 23%  610K 2s\n",
            "   300K .......... .......... .......... .......... .......... 27% 23.4M 2s\n",
            "   350K .......... .......... .......... .......... .......... 31%  625K 2s\n",
            "   400K .......... .......... .......... .......... .......... 35%  614K 2s\n",
            "   450K .......... .......... .......... .......... .......... 39% 23.7M 1s\n",
            "   500K .......... .......... .......... .......... .......... 43%  624K 1s\n",
            "   550K .......... .......... .......... .......... .......... 47% 27.1M 1s\n",
            "   600K .......... .......... .......... .......... .......... 51%  628K 1s\n",
            "   650K .......... .......... .......... .......... .......... 55% 68.5M 1s\n",
            "   700K .......... .......... .......... .......... .......... 59% 24.0M 1s\n",
            "   750K .......... .......... .......... .......... .......... 63%  626K 1s\n",
            "   800K .......... .......... .......... .......... .......... 67% 9.48M 1s\n",
            "   850K .......... .......... .......... .......... .......... 71% 96.5M 0s\n",
            "   900K .......... .......... .......... .......... .......... 75%  657K 0s\n",
            "   950K .......... .......... .......... .......... .......... 78% 89.4M 0s\n",
            "  1000K .......... .......... .......... .......... .......... 82% 5.44M 0s\n",
            "  1050K .......... .......... .......... .......... .......... 86%  690K 0s\n",
            "  1100K .......... .......... .......... .......... .......... 90% 71.3M 0s\n",
            "  1150K .......... .......... .......... .......... .......... 94% 5.45M 0s\n",
            "  1200K .......... .......... .......... .......... .......... 98%  693K 0s\n",
            "  1250K .......... .....                                      100% 78.3M=1.4s\n",
            "\n",
            "2018-08-29 08:48:46 (908 KB/s) - ‘protobuf.zip’ saved [1296281/1296281]\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "_tzDvSDphjI3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!./bin/protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NK2v-BPYjkUZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!cat ~/.bashrc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G1UIvEWwkjQd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#%%writefile ~/.bashrc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iEn_Bknira-A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "15cd2a39-ead5-41cc-cab9-2fa8f67f7e95"
      },
      "cell_type": "code",
      "source": [
        "%set_env PYTHONPATH=/content/models/research:/content/models/research/slim"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: PYTHONPATH=/content/models/research:/content/models/research/slim\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "54gURUkpn8ll",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "69418c6a-8d46-4d3c-c644-c6d8f72b391f"
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "echo $PYTHONPATH"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research:/content/models/research/slim\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kz0AHFmHhxaZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "db04e50e-c9bc-47f0-d32a-57a2b9dc52df"
      },
      "cell_type": "code",
      "source": [
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "..................\n",
            "----------------------------------------------------------------------\n",
            "Ran 18 tests in 0.111s\n",
            "\n",
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9J-Z1G13ssil",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Mount with Drive"
      ]
    },
    {
      "metadata": {
        "id": "YQOar1ixtBm1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Connecting with 1205006.mmh@ugrad.cse.buet.ac.bd"
      ]
    },
    {
      "metadata": {
        "id": "98alPsOd6V5H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#cd ../../"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lINudYdfBsR-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2528
        },
        "outputId": "d3f28856-9b35-449a-f73c-910c6baf7551"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package cron.\n",
            "(Reading database ... 18877 files and directories currently installed.)\n",
            "Preparing to unpack .../00-cron_3.0pl1-128ubuntu5_amd64.deb ...\n",
            "Unpacking cron (3.0pl1-128ubuntu5) ...\n",
            "Selecting previously unselected package libapparmor1:amd64.\n",
            "Preparing to unpack .../01-libapparmor1_2.11.0-2ubuntu17.1_amd64.deb ...\n",
            "Unpacking libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Selecting previously unselected package libdbus-1-3:amd64.\n",
            "Preparing to unpack .../02-libdbus-1-3_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Selecting previously unselected package dbus.\n",
            "Preparing to unpack .../03-dbus_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking dbus (1.10.22-1ubuntu1) ...\n",
            "Selecting previously unselected package dirmngr.\n",
            "Preparing to unpack .../04-dirmngr_2.1.15-1ubuntu8.1_amd64.deb ...\n",
            "Unpacking dirmngr (2.1.15-1ubuntu8.1) ...\n",
            "Selecting previously unselected package distro-info-data.\n",
            "Preparing to unpack .../05-distro-info-data_0.36ubuntu0.2_all.deb ...\n",
            "Unpacking distro-info-data (0.36ubuntu0.2) ...\n",
            "Selecting previously unselected package libkmod2:amd64.\n",
            "Preparing to unpack .../06-libkmod2_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Selecting previously unselected package kmod.\n",
            "Preparing to unpack .../07-kmod_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking kmod (24-1ubuntu2) ...\n",
            "Selecting previously unselected package lsb-release.\n",
            "Preparing to unpack .../08-lsb-release_9.20160110ubuntu5_all.deb ...\n",
            "Unpacking lsb-release (9.20160110ubuntu5) ...\n",
            "Selecting previously unselected package libgirepository-1.0-1:amd64.\n",
            "Preparing to unpack .../09-libgirepository-1.0-1_1.54.1-1_amd64.deb ...\n",
            "Unpacking libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package gir1.2-glib-2.0:amd64.\n",
            "Preparing to unpack .../10-gir1.2-glib-2.0_1.54.1-1_amd64.deb ...\n",
            "Unpacking gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package iso-codes.\n",
            "Preparing to unpack .../11-iso-codes_3.75-1_all.deb ...\n",
            "Unpacking iso-codes (3.75-1) ...\n",
            "Selecting previously unselected package libdbus-glib-1-2:amd64.\n",
            "Preparing to unpack .../12-libdbus-glib-1-2_0.108-2_amd64.deb ...\n",
            "Unpacking libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Selecting previously unselected package python-apt-common.\n",
            "Preparing to unpack .../13-python-apt-common_1.4.0~beta3build2_all.deb ...\n",
            "Unpacking python-apt-common (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-apt.\n",
            "Preparing to unpack .../14-python3-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python3-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-dbus.\n",
            "Preparing to unpack .../15-python3-dbus_1.2.4-1build3_amd64.deb ...\n",
            "Unpacking python3-dbus (1.2.4-1build3) ...\n",
            "Selecting previously unselected package python3-gi.\n",
            "Preparing to unpack .../16-python3-gi_3.24.1-2build1_amd64.deb ...\n",
            "Unpacking python3-gi (3.24.1-2build1) ...\n",
            "Selecting previously unselected package module-init-tools.\n",
            "Preparing to unpack .../17-module-init-tools_24-1ubuntu2_all.deb ...\n",
            "Unpacking module-init-tools (24-1ubuntu2) ...\n",
            "Selecting previously unselected package python-apt.\n",
            "Preparing to unpack .../18-python-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python-pycurl.\n",
            "Preparing to unpack .../19-python-pycurl_7.43.0-2build2_amd64.deb ...\n",
            "Unpacking python-pycurl (7.43.0-2build2) ...\n",
            "Selecting previously unselected package python-software-properties.\n",
            "Preparing to unpack .../20-python-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package python3-software-properties.\n",
            "Preparing to unpack .../21-python3-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python3-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package software-properties-common.\n",
            "Preparing to unpack .../22-software-properties-common_0.96.24.17_all.deb ...\n",
            "Unpacking software-properties-common (0.96.24.17) ...\n",
            "Selecting previously unselected package unattended-upgrades.\n",
            "Preparing to unpack .../23-unattended-upgrades_0.98ubuntu1.1_all.deb ...\n",
            "Unpacking unattended-upgrades (0.98ubuntu1.1) ...\n",
            "Setting up python-apt-common (1.4.0~beta3build2) ...\n",
            "Setting up python3-apt (1.4.0~beta3build2) ...\n",
            "Setting up iso-codes (3.75-1) ...\n",
            "Setting up distro-info-data (0.36ubuntu0.2) ...\n",
            "Setting up python-pycurl (7.43.0-2build2) ...\n",
            "Setting up lsb-release (9.20160110ubuntu5) ...\n",
            "Setting up libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Setting up libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Setting up gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Setting up unattended-upgrades (0.98ubuntu1.1) ...\n",
            "\n",
            "Creating config file /etc/apt/apt.conf.d/20auto-upgrades with new version\n",
            "\n",
            "Creating config file /etc/apt/apt.conf.d/50unattended-upgrades with new version\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up dirmngr (2.1.15-1ubuntu8.1) ...\n",
            "Setting up cron (3.0pl1-128ubuntu5) ...\n",
            "Adding group `crontab' (GID 102) ...\n",
            "Done.\n",
            "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
            "update-rc.d: warning: stop runlevel arguments (1) do not match cron Default-Stop values (none)\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Setting up kmod (24-1ubuntu2) ...\n",
            "Setting up libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Setting up python3-gi (3.24.1-2build1) ...\n",
            "Setting up module-init-tools (24-1ubuntu2) ...\n",
            "Setting up python3-software-properties (0.96.24.17) ...\n",
            "Setting up dbus (1.10.22-1ubuntu1) ...\n",
            "Setting up python-apt (1.4.0~beta3build2) ...\n",
            "Setting up python3-dbus (1.2.4-1build3) ...\n",
            "Setting up python-software-properties (0.96.24.17) ...\n",
            "Setting up software-properties-common (0.96.24.17) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Processing triggers for dbus (1.10.22-1ubuntu1) ...\n",
            "gpg: keybox '/tmp/tmpc4e3gtbo/pubring.gpg' created\n",
            "gpg: /tmp/tmpc4e3gtbo/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Selecting previously unselected package libfuse2:amd64.\n",
            "(Reading database ... 20285 files and directories currently installed.)\n",
            "Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package fuse.\n",
            "Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking fuse (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.6.21-0ubuntu2_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n",
            "Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up fuse (2.9.7-1ubuntu1) ...\n",
            "Setting up google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N2bcWIEAUfzi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "waaFi--zPLc2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "9a02510d-4e78-4535-d144-529ac188f2a1"
      },
      "cell_type": "code",
      "source": [
        "!ls drive"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Admission 2014\t data\t EEE 13 Rag Tour - Turja  L-3 T-II    Pictures\r\n",
            "Bizzybd\t\t deep\t Google Photos\t\t  MasumDrive  Programming\r\n",
            "Colab Notebooks  Digits  GRE Books\t\t  MasumDroid  Public\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TlFwz_Ca6F8J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Copy data from drive"
      ]
    },
    {
      "metadata": {
        "id": "-GCtd0Kz6pCM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4551dd98-acd8-428f-933c-bd4e24a87040"
      },
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/models/research'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "6MU_sv3roLhD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp -r drive/deep/data/object_detection_data/* object_detection/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QtjR0G4vN40f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "934851e3-02b2-4832-98a6-38a3d653993f"
      },
      "cell_type": "code",
      "source": [
        "cd object_detection/"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iyDGiz6PsNXo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training"
      ]
    },
    {
      "metadata": {
        "id": "AHJ60ORcSbGJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a7d5250e-23f1-4f64-ff98-6cdd1cfe9017"
      },
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/models/research/object_detection'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "sHFuWy9r3mJh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Don't run this cell\n",
        "\n",
        "`bash: line 1: 7095 Killed`"
      ]
    },
    {
      "metadata": {
        "id": "WnErZXNSAcbl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3581
        },
        "outputId": "57f66f07-6f9c-495e-e9c4-90edf428df66"
      },
      "cell_type": "code",
      "source": [
        "!cat ssdlite_mobilenet_v2_coco.config"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# SSDLite with Mobilenet v2 configuration for MSCOCO Dataset.\r\r\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\r\r\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\r\r\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\r\r\n",
            "# should be configured.\r\r\n",
            "\r\r\n",
            "model {\r\r\n",
            "  ssd {\r\r\n",
            "    num_classes: 5\r\r\n",
            "    box_coder {\r\r\n",
            "      faster_rcnn_box_coder {\r\r\n",
            "        y_scale: 10.0\r\r\n",
            "        x_scale: 10.0\r\r\n",
            "        height_scale: 5.0\r\r\n",
            "        width_scale: 5.0\r\r\n",
            "      }\r\r\n",
            "    }\r\r\n",
            "    matcher {\r\r\n",
            "      argmax_matcher {\r\r\n",
            "        matched_threshold: 0.5\r\r\n",
            "        unmatched_threshold: 0.5\r\r\n",
            "        ignore_thresholds: false\r\r\n",
            "        negatives_lower_than_unmatched: true\r\r\n",
            "        force_match_for_each_row: true\r\r\n",
            "      }\r\r\n",
            "    }\r\r\n",
            "    similarity_calculator {\r\r\n",
            "      iou_similarity {\r\r\n",
            "      }\r\r\n",
            "    }\r\r\n",
            "    anchor_generator {\r\r\n",
            "      ssd_anchor_generator {\r\r\n",
            "        num_layers: 6\r\r\n",
            "        min_scale: 0.2\r\r\n",
            "        max_scale: 0.95\r\r\n",
            "        aspect_ratios: 1.0\r\r\n",
            "        aspect_ratios: 2.0\r\r\n",
            "        aspect_ratios: 0.5\r\r\n",
            "        aspect_ratios: 3.0\r\r\n",
            "        aspect_ratios: 0.3333\r\r\n",
            "      }\r\r\n",
            "    }\r\r\n",
            "    image_resizer {\r\r\n",
            "      fixed_shape_resizer {\r\r\n",
            "        height: 300\r\r\n",
            "        width: 300\r\r\n",
            "      }\r\r\n",
            "    }\r\r\n",
            "    box_predictor {\r\r\n",
            "      convolutional_box_predictor {\r\r\n",
            "        min_depth: 0\r\r\n",
            "        max_depth: 0\r\r\n",
            "        num_layers_before_predictor: 0\r\r\n",
            "        use_dropout: false\r\r\n",
            "        dropout_keep_probability: 0.8\r\r\n",
            "        kernel_size: 3\r\r\n",
            "        use_depthwise: true\r\r\n",
            "        box_code_size: 4\r\r\n",
            "        apply_sigmoid_to_scores: false\r\r\n",
            "        conv_hyperparams {\r\r\n",
            "          activation: RELU_6,\r\r\n",
            "          regularizer {\r\r\n",
            "            l2_regularizer {\r\r\n",
            "              weight: 0.00004\r\r\n",
            "            }\r\r\n",
            "          }\r\r\n",
            "          initializer {\r\r\n",
            "            truncated_normal_initializer {\r\r\n",
            "              stddev: 0.03\r\r\n",
            "              mean: 0.0\r\r\n",
            "            }\r\r\n",
            "          }\r\r\n",
            "          batch_norm {\r\r\n",
            "            train: true,\r\r\n",
            "            scale: true,\r\r\n",
            "            center: true,\r\r\n",
            "            decay: 0.9997,\r\r\n",
            "            epsilon: 0.001,\r\r\n",
            "          }\r\r\n",
            "        }\r\r\n",
            "      }\r\r\n",
            "    }\r\r\n",
            "    feature_extractor {\r\r\n",
            "      type: 'ssd_mobilenet_v2'\r\r\n",
            "      min_depth: 16\r\r\n",
            "      depth_multiplier: 1.0\r\r\n",
            "      use_depthwise: true\r\r\n",
            "      conv_hyperparams {\r\r\n",
            "        activation: RELU_6,\r\r\n",
            "        regularizer {\r\r\n",
            "          l2_regularizer {\r\r\n",
            "            weight: 0.00004\r\r\n",
            "          }\r\r\n",
            "        }\r\r\n",
            "        initializer {\r\r\n",
            "          truncated_normal_initializer {\r\r\n",
            "            stddev: 0.03\r\r\n",
            "            mean: 0.0\r\r\n",
            "          }\r\r\n",
            "        }\r\r\n",
            "        batch_norm {\r\r\n",
            "          train: true,\r\r\n",
            "          scale: true,\r\r\n",
            "          center: true,\r\r\n",
            "          decay: 0.9997,\r\r\n",
            "          epsilon: 0.001,\r\r\n",
            "        }\r\r\n",
            "      }\r\r\n",
            "    }\r\r\n",
            "    loss {\r\r\n",
            "      classification_loss {\r\r\n",
            "        weighted_sigmoid {\r\r\n",
            "        }\r\r\n",
            "      }\r\r\n",
            "      localization_loss {\r\r\n",
            "        weighted_smooth_l1 {\r\r\n",
            "        }\r\r\n",
            "      }\r\r\n",
            "      hard_example_miner {\r\r\n",
            "        num_hard_examples: 3000\r\r\n",
            "        iou_threshold: 0.99\r\r\n",
            "        loss_type: CLASSIFICATION\r\r\n",
            "        max_negatives_per_positive: 3\r\r\n",
            "        min_negatives_per_image: 3\r\r\n",
            "      }\r\r\n",
            "      classification_weight: 1.0\r\r\n",
            "      localization_weight: 1.0\r\r\n",
            "    }\r\r\n",
            "    normalize_loss_by_num_matches: true\r\r\n",
            "    post_processing {\r\r\n",
            "      batch_non_max_suppression {\r\r\n",
            "        score_threshold: 1e-8\r\r\n",
            "        iou_threshold: 0.6\r\r\n",
            "        max_detections_per_class: 100\r\r\n",
            "        max_total_detections: 100\r\r\n",
            "      }\r\r\n",
            "      score_converter: SIGMOID\r\r\n",
            "    }\r\r\n",
            "  }\r\r\n",
            "}\r\r\n",
            "\r\r\n",
            "train_config: {\r\r\n",
            "  batch_size: 24\r\r\n",
            "  optimizer {\r\r\n",
            "    rms_prop_optimizer: {\r\r\n",
            "      learning_rate: {\r\r\n",
            "        exponential_decay_learning_rate {\r\r\n",
            "          initial_learning_rate: 0.004\r\r\n",
            "          decay_steps: 800720\r\r\n",
            "          decay_factor: 0.95\r\r\n",
            "        }\r\r\n",
            "      }\r\r\n",
            "      momentum_optimizer_value: 0.9\r\r\n",
            "      decay: 0.9\r\r\n",
            "      epsilon: 1.0\r\r\n",
            "    }\r\r\n",
            "  }\r\r\n",
            "  fine_tune_checkpoint: \"models/model.ckpt\"\r\r\n",
            "  fine_tune_checkpoint_type:  \"detection\"\r\r\n",
            "  # Note: The below line limits the training process to 200K steps, which we\r\r\n",
            "  # empirically found to be sufficient enough to train the pets dataset. This\r\r\n",
            "  # effectively bypasses the learning rate schedule (the learning rate will\r\r\n",
            "  # never decay). Remove the below line to train indefinitely.\r\r\n",
            "  num_steps: 200000\r\r\n",
            "  data_augmentation_options {\r\r\n",
            "    random_horizontal_flip {\r\r\n",
            "    }\r\r\n",
            "  }\r\r\n",
            "  data_augmentation_options {\r\r\n",
            "    ssd_random_crop {\r\r\n",
            "    }\r\r\n",
            "  }\r\r\n",
            "}\r\r\n",
            "\r\r\n",
            "train_input_reader: {\r\r\n",
            "  tf_record_input_reader {\r\r\n",
            "    input_path: \"data/train.record\"\r\r\n",
            "  }\r\r\n",
            "  label_map_path: \"nudity-detection.pbtxt\"\r\r\n",
            "}\r\r\n",
            "\r\r\n",
            "eval_config: {\r\r\n",
            "  num_examples: 396\r\r\n",
            "  # Note: The below line limits the evaluation process to 10 evaluations.\r\r\n",
            "  # Remove the below line to evaluate indefinitely.\r\r\n",
            "  max_evals: 10\r\r\n",
            "}\r\r\n",
            "\r\r\n",
            "eval_input_reader: {\r\r\n",
            "  tf_record_input_reader {\r\r\n",
            "    input_path: \"data/test.record\"\r\r\n",
            "  }\r\r\n",
            "  label_map_path: \"nudity-detection.pbtxt\"\r\r\n",
            "  shuffle: false\r\r\n",
            "  num_readers: 1\r\r\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qx2c3AU5Alrf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c7372e77-4001-4b95-bf9e-58733b7ac248"
      },
      "cell_type": "code",
      "source": [
        "%%writefile ssdlite_mobilenet_v2_coco.config\n",
        "# SSDLite with Mobilenet v2 configuration for MSCOCO Dataset.\n",
        "# Users should configure the fine_tune_checkpoint field in the train config as\n",
        "# well as the label_map_path and input_path fields in the train_input_reader and\n",
        "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
        "# should be configured.\n",
        "\n",
        "model {\n",
        "  ssd {\n",
        "    num_classes: 5\n",
        "    box_coder {\n",
        "      faster_rcnn_box_coder {\n",
        "        y_scale: 10.0\n",
        "        x_scale: 10.0\n",
        "        height_scale: 5.0\n",
        "        width_scale: 5.0\n",
        "      }\n",
        "    }\n",
        "    matcher {\n",
        "      argmax_matcher {\n",
        "        matched_threshold: 0.5\n",
        "        unmatched_threshold: 0.5\n",
        "        ignore_thresholds: false\n",
        "        negatives_lower_than_unmatched: true\n",
        "        force_match_for_each_row: true\n",
        "      }\n",
        "    }\n",
        "    similarity_calculator {\n",
        "      iou_similarity {\n",
        "      }\n",
        "    }\n",
        "    anchor_generator {\n",
        "      ssd_anchor_generator {\n",
        "        num_layers: 6\n",
        "        min_scale: 0.2\n",
        "        max_scale: 0.95\n",
        "        aspect_ratios: 1.0\n",
        "        aspect_ratios: 2.0\n",
        "        aspect_ratios: 0.5\n",
        "        aspect_ratios: 3.0\n",
        "        aspect_ratios: 0.3333\n",
        "      }\n",
        "    }\n",
        "    image_resizer {\n",
        "      fixed_shape_resizer {\n",
        "        height: 300\n",
        "        width: 300\n",
        "      }\n",
        "    }\n",
        "    box_predictor {\n",
        "      convolutional_box_predictor {\n",
        "        min_depth: 0\n",
        "        max_depth: 0\n",
        "        num_layers_before_predictor: 0\n",
        "        use_dropout: false\n",
        "        dropout_keep_probability: 0.8\n",
        "        kernel_size: 3\n",
        "        use_depthwise: true\n",
        "        box_code_size: 4\n",
        "        apply_sigmoid_to_scores: false\n",
        "        conv_hyperparams {\n",
        "          activation: RELU_6,\n",
        "          regularizer {\n",
        "            l2_regularizer {\n",
        "              weight: 0.00004\n",
        "            }\n",
        "          }\n",
        "          initializer {\n",
        "            truncated_normal_initializer {\n",
        "              stddev: 0.03\n",
        "              mean: 0.0\n",
        "            }\n",
        "          }\n",
        "          batch_norm {\n",
        "            train: true,\n",
        "            scale: true,\n",
        "            center: true,\n",
        "            decay: 0.9997,\n",
        "            epsilon: 0.001,\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    feature_extractor {\n",
        "      type: 'ssd_mobilenet_v2'\n",
        "      min_depth: 16\n",
        "      depth_multiplier: 1.0\n",
        "      use_depthwise: true\n",
        "      conv_hyperparams {\n",
        "        activation: RELU_6,\n",
        "        regularizer {\n",
        "          l2_regularizer {\n",
        "            weight: 0.00004\n",
        "          }\n",
        "        }\n",
        "        initializer {\n",
        "          truncated_normal_initializer {\n",
        "            stddev: 0.03\n",
        "            mean: 0.0\n",
        "          }\n",
        "        }\n",
        "        batch_norm {\n",
        "          train: true,\n",
        "          scale: true,\n",
        "          center: true,\n",
        "          decay: 0.9997,\n",
        "          epsilon: 0.001,\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    loss {\n",
        "      classification_loss {\n",
        "        weighted_sigmoid {\n",
        "        }\n",
        "      }\n",
        "      localization_loss {\n",
        "        weighted_smooth_l1 {\n",
        "        }\n",
        "      }\n",
        "      hard_example_miner {\n",
        "        num_hard_examples: 3000\n",
        "        iou_threshold: 0.99\n",
        "        loss_type: CLASSIFICATION\n",
        "        max_negatives_per_positive: 3\n",
        "        min_negatives_per_image: 3\n",
        "      }\n",
        "      classification_weight: 1.0\n",
        "      localization_weight: 1.0\n",
        "    }\n",
        "    normalize_loss_by_num_matches: true\n",
        "    post_processing {\n",
        "      batch_non_max_suppression {\n",
        "        score_threshold: 1e-8\n",
        "        iou_threshold: 0.6\n",
        "        max_detections_per_class: 100\n",
        "        max_total_detections: 100\n",
        "      }\n",
        "      score_converter: SIGMOID\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "train_config: {\n",
        "  batch_size: 2\n",
        "  optimizer {\n",
        "    rms_prop_optimizer: {\n",
        "      learning_rate: {\n",
        "        exponential_decay_learning_rate {\n",
        "          initial_learning_rate: 0.004\n",
        "          decay_steps: 800720\n",
        "          decay_factor: 0.95\n",
        "        }\n",
        "      }\n",
        "      momentum_optimizer_value: 0.9\n",
        "      decay: 0.9\n",
        "      epsilon: 1.0\n",
        "    }\n",
        "  }\n",
        "  fine_tune_checkpoint: \"models/model.ckpt\"\n",
        "  fine_tune_checkpoint_type:  \"detection\"\n",
        "  # Note: The below line limits the training process to 200K steps, which we\n",
        "  # empirically found to be sufficient enough to train the pets dataset. This\n",
        "  # effectively bypasses the learning rate schedule (the learning rate will\n",
        "  # never decay). Remove the below line to train indefinitely.\n",
        "  num_steps: 200000\n",
        "  data_augmentation_options {\n",
        "    random_horizontal_flip {\n",
        "    }\n",
        "  }\n",
        "  data_augmentation_options {\n",
        "    ssd_random_crop {\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "train_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"data/train.record\"\n",
        "  }\n",
        "  label_map_path: \"nudity-detection.pbtxt\"\n",
        "}\n",
        "\n",
        "eval_config: {\n",
        "  num_examples: 396\n",
        "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
        "  # Remove the below line to evaluate indefinitely.\n",
        "  max_evals: 10\n",
        "}\n",
        "\n",
        "eval_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"data/test.record\"\n",
        "  }\n",
        "  label_map_path: \"nudity-detection.pbtxt\"\n",
        "  shuffle: false\n",
        "  num_readers: 1\n",
        "}"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting ssdlite_mobilenet_v2_coco.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NUkz3Q3rP0-F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We should add the tensorboard here.\n",
        "\n",
        "check it after 3-4 hours"
      ]
    },
    {
      "metadata": {
        "id": "YF9Uq1TYsOdl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "python legacy/train.py --logtostderr --train_dir=./models/train --pipeline_config_path=ssdlite_mobilenet_v2_coco.config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wi0-Efv0BYVl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Other failed attempt"
      ]
    },
    {
      "metadata": {
        "id": "n9W3Bmpi3sZz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Run this cell"
      ]
    },
    {
      "metadata": {
        "id": "dCNhRAm85rv-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q pycocotools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c5KQ58z0SilN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 15055
        },
        "outputId": "c53d25e1-daac-4ebb-f37b-5c046f96764e"
      },
      "cell_type": "code",
      "source": [
        "!python model_main.py \\\n",
        "    --pipeline_config_path=ssdlite_mobilenet_v2_coco.config \\\n",
        "    --model_dir=/models/train \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps=3000 \\\n",
        "    --num_eval_steps=500"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection/utils/visualization_utils.py:25: UserWarning: \r\n",
            "This call to matplotlib.use() has no effect because the backend has already\r\n",
            "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\r\n",
            "or matplotlib.backends is imported for the first time.\r\n",
            "\r\n",
            "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\r\n",
            "  File \"model_main.py\", line 26, in <module>\r\n",
            "    from object_detection import model_lib\r\n",
            "  File \"/content/models/research/object_detection/model_lib.py\", line 26, in <module>\r\n",
            "    from object_detection import eval_util\r\n",
            "  File \"/content/models/research/object_detection/eval_util.py\", line 28, in <module>\r\n",
            "    from object_detection.metrics import coco_evaluation\r\n",
            "  File \"/content/models/research/object_detection/metrics/coco_evaluation.py\", line 20, in <module>\r\n",
            "    from object_detection.metrics import coco_tools\r\n",
            "  File \"/content/models/research/object_detection/metrics/coco_tools.py\", line 47, in <module>\r\n",
            "    from pycocotools import coco\r\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/coco.py\", line 49, in <module>\r\n",
            "    import matplotlib.pyplot as plt\r\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\", line 72, in <module>\r\n",
            "    from matplotlib.backends import pylab_setup\r\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/backends/__init__.py\", line 14, in <module>\r\n",
            "    line for line in traceback.format_stack()\r\n",
            "\r\n",
            "\r\n",
            "  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f25a4980b70>) includes params argument, but params are not passed to Estimator.\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:1205: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use the `axis` argument instead\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:146: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "2018-08-29 08:58:17.296092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-08-29 08:58:17.296608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2018-08-29 08:58:17.296666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\n",
            "2018-08-29 08:58:17.605729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-08-29 08:58:17.605810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 \n",
            "2018-08-29 08:58:17.605856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N \n",
            "2018-08-29 08:58:17.606184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10759 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2018-08-29 08:58:49.477771: W tensorflow/core/framework/allocator.cc:108] Allocation of 24883200 exceeds 10% of system memory.\n",
            "2018-08-29 08:58:49.515702: W tensorflow/core/framework/allocator.cc:108] Allocation of 24883200 exceeds 10% of system memory.\n",
            "2018-08-29 08:58:49.528243: W tensorflow/core/framework/allocator.cc:108] Allocation of 24883200 exceeds 10% of system memory.\n",
            "2018-08-29 08:58:49.589955: W tensorflow/core/framework/allocator.cc:108] Allocation of 24883200 exceeds 10% of system memory.\n",
            "2018-08-29 08:58:49.600480: W tensorflow/core/framework/allocator.cc:108] Allocation of 24883200 exceeds 10% of system memory.\n",
            "2018-08-29 09:08:52.475232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\n",
            "2018-08-29 09:08:52.475367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-08-29 09:08:52.475412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 \n",
            "2018-08-29 09:08:52.475433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N \n",
            "2018-08-29 09:08:52.475692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10759 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 591836186 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 591836186 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 679274871 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 679274871 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 679274871 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 679274871 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 778000536 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 778000536 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1327713343 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1327713343 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1327713343 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1327713343 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1327713343 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1327713343 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 893376556 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 893376556 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1401623745 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1401623745 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 980647961 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 980647961 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 847275035 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 847275035 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 542539156 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 542539156 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 795236273 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 795236273 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1260609148 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1260609148 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1775807881 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1775807881 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 270032133 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 270032133 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 270032133 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 270032133 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 270032133 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 270032133 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 270032133 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 270032133 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1767628872 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1767628872 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1767628872 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1767628872 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 464614444 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 464614444 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1056236762 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1056236762 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1898735017 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1898735017 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1898735017 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1898735017 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 595325922 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 595325922 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 347150850 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 347150850 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1852252154 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1852252154 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1500261894 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1500261894 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 896508295 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 896508295 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 896508295 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 896508295 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 225218906 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 225218906 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1598510943 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1598510943 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 962515115 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 962515115 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 152870792 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 152870792 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 235756402 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 235756402 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 324725218 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 324725218 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 435211123 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 435211123 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 490819898 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 490819898 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 889519269 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 889519269 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 889519269 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 889519269 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1691537356 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1691537356 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1258759453 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1258759453 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1209774288 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1209774288 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 311584643 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 311584643 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 612399976 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 612399976 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1530393189 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1530393189 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1736134861 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1736134861 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 461943262 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 461943262 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1905437767 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1905437767 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1063437453 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1063437453 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1063437453 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1063437453 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1201985772 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1201985772 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 618099958 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 618099958 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 618099958 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 618099958 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 618099958 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 618099958 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 5544590 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 5544590 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 5544590 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 5544590 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 5544590 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 5544590 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1149172147 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1149172147 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1149172147 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1149172147 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1149172147 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1149172147 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1149172147 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1149172147 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 271518637 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 271518637 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 271518637 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 271518637 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1360880287 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1360880287 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1360880287 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1360880287 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 959796301 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 959796301 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 959796301 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 959796301 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 959796301 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 959796301 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 959796301 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 959796301 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 202941062 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 202941062 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 202941062 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 202941062 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 202941062 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 202941062 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 940496188 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 940496188 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 940496188 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 940496188 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 33012722 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 33012722 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 33012722 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 33012722 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 33012722 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 33012722 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 33012722 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 33012722 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 380160845 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 380160845 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1955448031 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1955448031 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 960649173 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 960649173 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 960649173 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 960649173 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 314211774 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 314211774 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 314211774 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 314211774 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 314211774 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 314211774 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 274978527 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 274978527 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1193544887 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1193544887 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 708883627 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 708883627 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 331666356 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 331666356 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1328563489 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1328563489 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1328563489 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1328563489 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1591238354 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1591238354 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1591238354 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1591238354 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1176886819 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1176886819 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1117054045 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1117054045 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1117054045 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1117054045 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1821491634 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1821491634 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 730761504 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 730761504 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 730761504 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 730761504 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 730761504 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 730761504 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1069244877 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1069244877 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 193874753 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 193874753 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 708121370 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 708121370 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 19957298 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 19957298 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 19957298 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 19957298 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 19957298 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 19957298 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1961944900 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1961944900 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 924535244 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 924535244 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 98612202 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 98612202 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 370169972 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 370169972 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 434836038 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 434836038 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 434836038 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 434836038 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 434836038 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 434836038 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1197134121 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1197134121 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1197134121 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1197134121 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 760990837 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 760990837 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1428953909 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1428953909 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1001976014 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1001976014 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1001976014 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1001976014 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1001976014 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1001976014 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1001976014 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1001976014 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1695396226 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1695396226 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1086607249 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1086607249 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 546248787 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 546248787 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 546248787 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 546248787 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1863172112 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1863172112 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1863172112 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1863172112 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1116034695 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1116034695 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1116034695 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1116034695 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1116034695 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1116034695 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 805338972 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 805338972 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1818045613 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1818045613 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1818045613 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1818045613 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1818045613 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1818045613 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 149116753 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 149116753 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 149116753 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 149116753 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 149116753 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 149116753 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 149116753 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 149116753 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1250282464 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1250282464 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1250282464 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1250282464 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1250282464 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1250282464 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1250282464 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1250282464 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1250282464 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1250282464 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1109653849 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1109653849 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 745020973 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 745020973 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 745020973 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 745020973 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1876789355 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1876789355 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1876789355 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1876789355 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1876789355 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1876789355 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1744149532 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1744149532 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1097900890 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1097900890 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 623638677 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 623638677 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 2137413683 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 2137413683 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 606656468 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 606656468 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 889385417 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 889385417 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 357570630 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 357570630 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 2081241393 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 2081241393 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 904820737 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 904820737 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1727028961 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1727028961 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1674312579 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1674312579 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 91237791 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 91237791 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1972484072 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1972484072 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 591836186 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 591836186 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 591836186 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 591836186 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 679274871 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 679274871 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 679274871 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 679274871 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 679274871 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 679274871 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 778000536 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 778000536 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 778000536 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 778000536 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1327713343 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1327713343 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1327713343 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1327713343 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1327713343 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1327713343 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1327713343 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1327713343 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 893376556 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 893376556 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 893376556 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 893376556 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1376806383 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1376806383 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1401623745 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1401623745 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1401623745 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1401623745 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1634719389 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1634719389 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 980647961 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 980647961 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 980647961 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 980647961 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1723885593 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1723885593 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 847275035 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 847275035 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 847275035 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 847275035 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 542539156 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 542539156 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 542539156 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 542539156 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 795236273 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 795236273 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 795236273 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 795236273 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1260609148 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1260609148 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1260609148 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1260609148 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1681626549 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1681626549 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1775807881 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1775807881 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1775807881 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1775807881 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 270032133 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 270032133 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 270032133 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 270032133 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 270032133 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 270032133 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 270032133 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 270032133 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 270032133 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 270032133 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1767628872 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1767628872 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1767628872 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1767628872 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1767628872 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1767628872 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 67862014 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 67862014 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 464614444 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 464614444 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 464614444 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 464614444 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 298963181 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 298963181 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1056236762 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1056236762 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1056236762 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1056236762 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1898735017 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1898735017 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1898735017 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1898735017 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1898735017 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1898735017 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 595325922 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 595325922 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 595325922 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 595325922 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 347150850 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 347150850 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 347150850 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 347150850 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 2057032492 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 2057032492 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1852252154 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1852252154 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1852252154 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1852252154 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1526118907 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1526118907 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1419237084 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1419237084 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1785402268 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1785402268 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1500261894 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1500261894 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1500261894 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1500261894 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 60065815 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 60065815 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 36493001 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 36493001 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 962292782 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 962292782 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 691547315 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 691547315 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1002664798 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1002664798 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 888145508 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 888145508 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 896508295 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 896508295 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 896508295 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 896508295 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 896508295 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 896508295 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 225218906 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 225218906 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 225218906 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 225218906 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 612796252 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 612796252 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1383313744 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1383313744 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1208449147 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1208449147 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1989970710 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1989970710 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 796308681 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 796308681 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 940228291 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 940228291 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 396292353 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 396292353 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1585338905 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1585338905 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1750901182 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1750901182 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1598510943 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1598510943 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1598510943 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1598510943 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 962515115 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 962515115 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 962515115 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 962515115 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 740414368 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 740414368 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 152870792 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 152870792 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 152870792 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 152870792 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 235756402 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 235756402 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 235756402 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 235756402 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 12016935 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 12016935 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 324725218 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 324725218 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 324725218 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 324725218 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1038559061 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1038559061 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1401339640 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1401339640 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 709250167 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 709250167 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 329689374 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 329689374 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 435211123 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 435211123 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 435211123 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 435211123 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1619637247 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1619637247 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 490819898 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 490819898 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 490819898 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 490819898 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1417476130 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1417476130 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 889519269 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 889519269 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 889519269 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 889519269 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 889519269 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 889519269 since it was previously added\n",
            "WARNING:tensorflow:Ignoring ground truth with image id 1297462654 since it was previously added\n",
            "WARNING:tensorflow:Ignoring detection with image id 1297462654 since it was previously added\n",
            "creating index...\n",
            "index created!\n",
            "2018-08-29 09:09:34.241439: W tensorflow/core/framework/op_kernel.cc:1263] Invalid argument: TypeError: can't pickle dict_values objects\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 206, in __call__\n",
            "    ret = func(*args)\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_evaluation.py\", line 332, in first_value_func\n",
            "    self._metrics = self.evaluate()\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_evaluation.py\", line 193, in evaluate\n",
            "    self._detection_boxes_list)\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_tools.py\", line 118, in LoadAnnotations\n",
            "    results.dataset['categories'] = copy.deepcopy(self.dataset['categories'])\n",
            "\n",
            "  File \"/usr/lib/python3.6/copy.py\", line 169, in deepcopy\n",
            "    rv = reductor(4)\n",
            "\n",
            "TypeError: can't pickle dict_values objects\n",
            "\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1278, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1263, in _run_fn\n",
            "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1350, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: TypeError: can't pickle dict_values objects\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 206, in __call__\n",
            "    ret = func(*args)\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_evaluation.py\", line 332, in first_value_func\n",
            "    self._metrics = self.evaluate()\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_evaluation.py\", line 193, in evaluate\n",
            "    self._detection_boxes_list)\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_tools.py\", line 118, in LoadAnnotations\n",
            "    results.dataset['categories'] = copy.deepcopy(self.dataset['categories'])\n",
            "\n",
            "  File \"/usr/lib/python3.6/copy.py\", line 169, in deepcopy\n",
            "    rv = reductor(4)\n",
            "\n",
            "TypeError: can't pickle dict_values objects\n",
            "\n",
            "\n",
            "\t [[Node: PyFunc_1 = PyFunc[Tin=[], Tout=[DT_FLOAT], token=\"pyfunc_3\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
            "\t [[Node: Postprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/non_max_suppression_3/NonMaxSuppressionV3/_2813 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_1613_...pressionV3\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"model_main.py\", line 101, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\n",
            "    _sys.exit(main(argv))\n",
            "  File \"model_main.py\", line 97, in main\n",
            "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\", line 451, in train_and_evaluate\n",
            "    return executor.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\", line 590, in run\n",
            "    return self.run_local()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\", line 691, in run_local\n",
            "    saving_listeners=saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 376, in train\n",
            "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1145, in _train_model\n",
            "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1173, in _train_model_default\n",
            "    saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1451, in _train_with_estimator_spec\n",
            "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 583, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1059, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1150, in run\n",
            "    raise six.reraise(*original_exc_info)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/six.py\", line 693, in reraise\n",
            "    raise value\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1135, in run\n",
            "    return self._sess.run(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1215, in run\n",
            "    run_metadata=run_metadata))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 464, in after_run\n",
            "    if self._save(run_context.session, global_step):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 489, in _save\n",
            "    if l.after_save(session, step):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\", line 497, in after_save\n",
            "    self._evaluate(global_step_value)  # updates self.eval_result\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\", line 517, in _evaluate\n",
            "    self._evaluator.evaluate_and_export())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\", line 884, in evaluate_and_export\n",
            "    hooks=self._eval_spec.hooks)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 470, in evaluate\n",
            "    output_dir=self.eval_dir(name))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1501, in _evaluate_run\n",
            "    config=self._session_config)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/evaluation.py\", line 212, in _evaluate_once\n",
            "    session.run(eval_ops, feed_dict)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 695, in __exit__\n",
            "    self._close_internal(exception_type)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 727, in _close_internal\n",
            "    h.end(self._coordinated_creator.tf_sess)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 824, in end\n",
            "    self._final_ops, feed_dict=self._final_ops_feed_dict)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 877, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1100, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1272, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1291, in _do_call\n",
            "    raise type(e)(node_def, op, message)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: TypeError: can't pickle dict_values objects\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 206, in __call__\n",
            "    ret = func(*args)\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_evaluation.py\", line 332, in first_value_func\n",
            "    self._metrics = self.evaluate()\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_evaluation.py\", line 193, in evaluate\n",
            "    self._detection_boxes_list)\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_tools.py\", line 118, in LoadAnnotations\n",
            "    results.dataset['categories'] = copy.deepcopy(self.dataset['categories'])\n",
            "\n",
            "  File \"/usr/lib/python3.6/copy.py\", line 169, in deepcopy\n",
            "    rv = reductor(4)\n",
            "\n",
            "TypeError: can't pickle dict_values objects\n",
            "\n",
            "\n",
            "\t [[Node: PyFunc_1 = PyFunc[Tin=[], Tout=[DT_FLOAT], token=\"pyfunc_3\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
            "\t [[Node: Postprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/non_max_suppression_3/NonMaxSuppressionV3/_2813 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_1613_...pressionV3\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
            "\n",
            "Caused by op 'PyFunc_1', defined at:\n",
            "  File \"model_main.py\", line 101, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\n",
            "    _sys.exit(main(argv))\n",
            "  File \"model_main.py\", line 97, in main\n",
            "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\", line 451, in train_and_evaluate\n",
            "    return executor.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\", line 590, in run\n",
            "    return self.run_local()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\", line 691, in run_local\n",
            "    saving_listeners=saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 376, in train\n",
            "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1145, in _train_model\n",
            "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1173, in _train_model_default\n",
            "    saving_listeners)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1451, in _train_with_estimator_spec\n",
            "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 583, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1059, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1135, in run\n",
            "    return self._sess.run(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1215, in run\n",
            "    run_metadata=run_metadata))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 464, in after_run\n",
            "    if self._save(run_context.session, global_step):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 489, in _save\n",
            "    if l.after_save(session, step):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\", line 497, in after_save\n",
            "    self._evaluate(global_step_value)  # updates self.eval_result\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\", line 517, in _evaluate\n",
            "    self._evaluator.evaluate_and_export())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\", line 884, in evaluate_and_export\n",
            "    hooks=self._eval_spec.hooks)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 463, in evaluate\n",
            "    input_fn, hooks, checkpoint_path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1463, in _evaluate_build_graph\n",
            "    features, labels, model_fn_lib.ModeKeys.EVAL, self.config)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1133, in _call_model_fn\n",
            "    model_fn_results = self._model_fn(features=features, **kwargs)\n",
            "  File \"/content/models/research/object_detection/model_lib.py\", line 391, in model_fn\n",
            "    eval_dict)\n",
            "  File \"/content/models/research/object_detection/eval_util.py\", line 656, in get_eval_metric_ops_for_evaluators\n",
            "    eval_dict))\n",
            "  File \"/content/models/research/object_detection/metrics/coco_evaluation.py\", line 342, in get_estimator_eval_metric_ops\n",
            "    first_value_op = tf.py_func(first_value_func, [], tf.float32)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 456, in py_func\n",
            "    func=func, inp=inp, Tout=Tout, stateful=stateful, eager=False, name=name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 281, in _internal_py_func\n",
            "    input=inp, token=token, Tout=Tout, name=name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_script_ops.py\", line 128, in py_func\n",
            "    \"PyFunc\", input=input, token=token, Tout=Tout, name=name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n",
            "    self._traceback = tf_stack.extract_stack()\n",
            "\n",
            "InvalidArgumentError (see above for traceback): TypeError: can't pickle dict_values objects\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 206, in __call__\n",
            "    ret = func(*args)\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_evaluation.py\", line 332, in first_value_func\n",
            "    self._metrics = self.evaluate()\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_evaluation.py\", line 193, in evaluate\n",
            "    self._detection_boxes_list)\n",
            "\n",
            "  File \"/content/models/research/object_detection/metrics/coco_tools.py\", line 118, in LoadAnnotations\n",
            "    results.dataset['categories'] = copy.deepcopy(self.dataset['categories'])\n",
            "\n",
            "  File \"/usr/lib/python3.6/copy.py\", line 169, in deepcopy\n",
            "    rv = reductor(4)\n",
            "\n",
            "TypeError: can't pickle dict_values objects\n",
            "\n",
            "\n",
            "\t [[Node: PyFunc_1 = PyFunc[Tin=[], Tout=[DT_FLOAT], token=\"pyfunc_3\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
            "\t [[Node: Postprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/non_max_suppression_3/NonMaxSuppressionV3/_2813 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_1613_...pressionV3\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uhGWAjDj5Ciw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}